# readAllLevelFiles ------------------------------------------------------------

#' Read all Level Files
#' 
#' @param levelFiles vector of file paths
#' @param dbg if \code{TRUE}, debug messages are shown.
#' 
#' @export
#' 
readAllLevelFiles <- function(levelFiles, dbg = TRUE)
{
  levelData <- NULL

  for (levelFile in levelFiles) {

    if (dbg) {
      cat("Reading", levelFile, "...\n")
    }

    newLevelData <- kwb.logger::readLogger_Ori_MLog(
      levelFile, sep = ";", stopOnMissingColumns = FALSE)

    newLevelData <- data.frame(
      file = basename(levelFile),
      row = 1:nrow(newLevelData),
      newLevelData,
      stringsAsFactors = FALSE)

    if (dbg) {
      cat("- Columns:", paste(kwb.utils::hsQuoteChr(names(newLevelData))), "\n")
      cat("ok.\n")
    }

    levelData <- kwb.utils::safeRowBind(levelData, newLevelData)
  }

  levelData
}

# getLevelFilesForSite ---------------------------------------------------------

#' Level Files for Site

#' @param config configuration object (list) with elements "dictionaryFile" and
#'   elements required by \code{\link[kwb.monitoring]{pathDictionary}}
#' @param station name of monitoring station
#' @return vector of file paths
#' @export
getLevelFilesForSite <- function(config, station)
{
  config$station <- station

  dictionary <- kwb.monitoring::pathDictionary(
    dictionaryFile = config$dictionaryFile,
    settings = config
  )

  getDswtFilePaths(
    kwb.utils::resolve("LEVEL_DATA_DIR", dictionary),
    DSWT_FILE_TYPES()$RADAR_PROBE_H
  )
}

# getDswtFilePaths -------------------------------------------------------------

#' Get DSWT File Paths
#' 
#' Browse for files of given type (DSWT-specific)
#' 
#' @param srcdir source directory
#' @param filetype one of the file types contained in DSWT_FILE_TYPES
#' @param recursive search in subdirectories?
#' @return vector of file paths
#' @export
getDswtFilePaths <- function(srcdir, filetype, recursive = FALSE)
{
  srcfiles <- dir(srcdir, pattern = filetype$pattern, full.names = TRUE,
                  recursive = recursive)

  if (kwb.utils::isNullOrEmpty(srcfiles)) {
    warning(sprintf("No files matching pattern '%s' found in %s\n",
                    filetype$pattern, srcdir))
    return()
  }

  srcfiles
}

# dirUploadedFiles -------------------------------------------------------------

#' List Uploaded Files
#' 
#' @param full.names if \code{TRUE} the full absolute URLs are returned, 
#'   otherwise only the relative paths.
#'   
#' @return list with elements \emph{PN}, \emph{H}, \emph{RD}, \emph{F},
#'   \emph{LPR}, \emph{Q}, \emph{BPR} containing URLs to sampler files, water
#'   level files, rain data files, photos, laboratory protocol files, discharge
#'   files and operation protocol files, respectively, that are available at the
#'   DSWT server at sysprovide.de
#'   
#' @export
#' 
dirUploadedFiles <- function(full.names = FALSE)
{
  url <- "ftp://srv1-18557.srv-net.de/html/uploaded_files"
  subdirs <- c("PN", "H", "RD", "F", "LPR", "Q", "BPR")

  filepaths <- file.path(url, subdirs, "")
  names(filepaths)   <- subdirs

  uploadedFiles <- list()

  for (subdir in subdirs) {
    
    filenames <- dirFtpPath(
      filepaths[subdir], 
      userpwd = Sys.getenv()["DSWT_FTP_LOGIN"],
      full.names
    )

    uploadedFiles[[subdir]] <- filenames
  }

  uploadedFiles
}

# dirFtpPath -------------------------------------------------------------------

#' List Files on FTP Server 
#' 
#' @param url base url in which to look for files
#' @param userpwd user and password, separated by colon ":"
#' @param full.names logical (default: \code{FALSE}). Determines whether to
#'   return relative paths or the full URLs including the base \code{url}
#'   
#' @return vector of urls or relative paths
#' 
#' @export
#' 
dirFtpPath <- function(url, userpwd, full.names = FALSE)
{
  if (! requireNamespace("RCurl", quietly = TRUE)) {
    stop("Please install the package 'RCurl' first with ",
         "install.packages(\"RCurl\") in order to run dirFtpPath()")
  }

  filenames <- RCurl::getURL(url, userpwd = userpwd, ftp.use.epsv = FALSE,
                             dirlistonly = TRUE)
  filenames <- strsplit(filenames, "\r\n")[[1]]
  filenames <- setdiff(filenames, c(".", ".."))

  if (full.names) {
    filenames <- file.path(sub("/$", "", url), filenames)
  }

  filenames
}

# getHQSeriesFromCSV -----------------------------------------------------------

#' Get H and Q Series from CSV File
#' 
#' @param srcfile full path to csv file generated by radar probe
#' @param DN DN in mm. Must be one of 150, 300.
#' @param sep column separator. Default: Tabulator "\\t"
#' @param timeFormat format of timestamp. Default: "\%d.\%m.\%Y \%H:\%M"
#' @param hoffset level offset to be subtracted from the measured level in order
#'   to get the level above the flume
#' @param addTimeColumns if TRUE, time columns containing local date and time
#'   are added
#' @param additionalColumns names of additional columns to be imported. One of
#'   c("I_mA", "Battery_V", "DeviceID")
#' @param \dots further arguments passed to readLogger_Ori_MLog, e.g.
#'   \emph{stopOnMissingColumns}
#'
#' @return data frame with columns \emph{BerlinDateTimeNoDST} (no daylight
#'   saving time adjustment!), \emph{Hraw_m} (measured height in m), \emph{H_m }
#'   (corrected height [= measured height minus offset] in m),\emph{Q_L_s}
#'   (calculated discharge in L/s). If \emph{addTimeColumns} is TRUE the columns
#'   \emph{BerlinDateTime} and \emph{UTCOffset} will be added.
#'   
#' @export
#' 
getHQSeriesFromCSV <- function(
  srcfile, DN, sep = "\t", timeFormat = NULL, hoffset = 0.02,
  addTimeColumns = TRUE, additionalColumns = c("I_mA", "Battery_V"), ...
)
{
  if (is.null(timeFormat)) {
    timeFormat <- c("%d.%m.%Y %H:%M:%S", "%d.%m.%Y %H:%M")
  }

  myData <- kwb.logger::readLogger_Ori_MLog(srcfile, sep = sep, timeFormat = timeFormat, ...)

  if ("Level_cm" %in% names(myData)) {
    myData <- kwb.utils::hsRenameColumns(myData, list(Level_cm = "Hraw_cm"))
  }

  if (!"Hraw_m" %in% names(myData)) {
    kwb.utils::checkForMissingColumns(myData, "Hraw_cm")

    # convert cm to m and rename column
    myData$Hraw_cm <- myData$Hraw_cm / 100
    myData <- kwb.utils::hsRenameColumns(myData, list(Hraw_cm = "Hraw_m"))
  }

  hdat <- data.frame(
    BerlinDateTimeNoDST = myData$myDateTime,
    Hraw_m = myData$Hraw_m,
    stringsAsFactors = FALSE)

  if (length(additionalColumns) > 0) {
    hdat <- cbind(hdat, myData[, additionalColumns])
  }

  hdat <- correctHandCalculateQ(hdat, hoffset = hoffset, DN = DN)

  if (isTRUE(addTimeColumns)) {
    hdat <- insertLocalDateTimeColumns(hdat)
  }

  hdat
}

# correctHandCalculateQ --------------------------------------------------------

#' Correct Level with Offset and Calculate Q
#' 
#' @param hdat data frame containing at least a column \emph{Hraw_m}, as e.g.
#'   retrieved by \code{readLogger_Ori_MLog}
#' @param hoffset offset in m to be subtracted from raw levels before the HQ
#'   relationship is applied
#' @param DN DN in mm, must be one of 150, 300
#'
#' @return data frame with additional columns \emph{H_m, Q_L_s}
#' 
correctHandCalculateQ <- function(hdat, hoffset, DN)
{
  hdat$H_m <- hdat$Hraw_m - hoffset

  # Set H to 0 for H < 0
  hdat$H_m[hdat$H_m < 0] <- 0

  # calculate flow Q from H
  hdat$Q_L_s <- H_to_Q(hdat$H_m, DN)

  hdat
}

# insertLocalDateTimeColumns ---------------------------------------------------

#' Insert LocalDateTime Columns
#' 
#' @param mydata data frame with character column \emph{BerlinDateTimeNoDST}
#' 
#' @return data frame with additional columns \emph{BerlinDateTime} (character),
#'   \emph{UTCOffset} (numeric)
#' 
#' @export
#' 
insertLocalDateTimeColumns <- function(mydata)
{
  colname <- "BerlinDateTimeNoDST"
  winterTimeCol <- which(names(mydata) == colname)

  if(length(winterTimeCol) != 1) {
    stop(sprintf("No column \"%s\" found in data frame \"mydata\"!", colname))
  }

  berlinTime <- kwb.datetime::berlinNormalTimeToBerlinLocalTime(mydata[[winterTimeCol]])
  utcTime <- kwb.datetime::berlinNormalTimeToUTC(mydata[[winterTimeCol]])

  timesOnly <- data.frame(
    BerlinDateTimeNoDST = mydata[[winterTimeCol]],
    BerlinDateTime = berlinTime,
    UTCOffset = kwb.datetime::utcOffset(berlinTime, utcTime),
    stringsAsFactors = FALSE
  )
  
  dataOnly <- mydata[, -winterTimeCol, drop = FALSE]

  cbind(timesOnly, dataOnly)
}

# insertUtcDateTimeColumn ------------------------------------------------------

#' Insert DateTimeUTC Column
#' 
#' @param mydata data frame with column \code{BerlinDateTimeNoDST}
#' 
#' @return mydata with additional column \emph{DateTimeUTC}
#' 
#' @export
#' 
insertUtcDateTimeColumn <- function(mydata)
{
  utcTime <- kwb.datetime::berlinNormalTimeToUTC(mydata$BerlinDateTimeNoDST)
  
  cbind(mydata, DateTimeUTC = utcTime, stringsAsFactors = FALSE)
}

# completeTimeColumns ----------------------------------------------------------

#' Complete Time Columns
#' 
#' @param x data frame with time columns
#' @param wanted Default: c("BerlinDateTime", "UTCOffset", "DateTimeUTC")
#' 
#' @return (Hopefully) data frame with columns \emph{BerlinDateTimeNoDST},
#'   \emph{BerlinDateTime}, \emph{UTCOffset}, \emph{DateTimeUTC},
#' 
completeTimeColumns <- function(
  x, wanted = c("BerlinDateTime", "UTCOffset", "DateTimeUTC")
)
{
  cnames <- names(x)
  berlinTime <- NULL

  if (.wantedButNotAvailable("BerlinDateTime", wanted, cnames)) {
    if ("BerlinDateTimeNoDST" %in% cnames) {
      #berlinTime <- berlinWinterTimeToBerlinLocalTime(as.character(x$BerlinDateTimeNoDST))
      #x$BerlinDateTime <- berlinTime$charLocal
      x$BerlinDateTime <- kwb.datetime::berlinNormalTimeToBerlinLocalTime(as.character(x$BerlinDateTimeNoDST))
    }
  }

  if (.wantedButNotAvailable("UTCOffset", wanted, cnames)) {
    if (is.null(berlinTime) && "BerlinDateTimeNoDST" %in% cnames) {
      #berlinTime <- berlinWinterTimeToBerlinLocalTime(as.character(x$BerlinDateTimeNoDST))
      #x$UTCOffset <- berlinTime$utcOffset
      bnt <- as.character(x$BerlinDateTimeNoDST)
      x$UTCOffset <- kwb.datetime::utcOffset(
        kwb.datetime::berlinNormalTimeToBerlinLocalTime(bnt),
        kwb.datetime::berlinNormalTimeToUTC(bnt)
      )
    }
  }

  if (.wantedButNotAvailable("DateTimeUTC", wanted, cnames)) {
    if ("BerlinDateTimeNoDST" %in% cnames) {
      #utcTime <- berlinWinterTimeToUTC(as.character(x$BerlinDateTimeNoDST))
      #x$DateTimeUTC <- utcTime$charUTC
      x$DateTimeUTC <- kwb.datetime::berlinNormalTimeToUTC(as.character(x$BerlinDateTimeNoDST))
    }
  }
  x
}

# addTotalVolumeAndMaxQ --------------------------------------------------------

#' Add Total Volume and Max Q
#' 
#' @param qValues vector of discharge values given in L/s
#' @param events event information as retrieved by \code{kwb.event::hsEvents}
#' @param eventnr integer vector of same length as \emph{qValues} giving the
#'   number of the event to which the Q value belongs, as returned by
#'   \code{kwb.event::hsEventNumber}.
#' @param digitsV number of decimal places for V in m3
#' @param digitsMaxQ number of decimal places for max. Q in L/s
#'
#' @return \emph{events} with columns \emph{V_m3} and \emph{maxQ_L_s} added
#' 
#' @export
#' 
addTotalVolumeAndMaxQ <- function(
  qValues, events, eventnr, digitsV = 3, digitsMaxQ = 3
)
{
  # calculate total volume and max flow per event
  myby <- list(eventnr=eventnr)
  qsum <- stats::aggregate(qValues, by=myby, FUN=sum)
  qmax <- stats::aggregate(qValues, by=myby, FUN=max)

  signalWidth <- kwb.event::hsSigWidth(events)
  cat(sprintf(
    "A signal width of %d seconds was deduced from the event list.\n",
    signalWidth
  ))
  
  events$V_m3 <- round(qsum$x / 1000 * signalWidth, digitsV)
  events$maxQ_L_s <- round(qmax$x, digitsMaxQ)

  events
}

# reformatEvents ---------------------------------------------------------------

#' Reformat Event List
#' 
#' Reformat event list: convert to minutes and rename columns
#' 
#' @param events event list as retrieved by \code{kwb.event::hsEvents}
#' 
#' @return \emph{events} with \emph{tBeg} renamed \emph{Ereignisbeginn_UTC},
#'   \emph{tEnd} renamed \emph{Ereignisende_UTC}, \emph{dur} renamed
#'   \emph{Dauer_min}, \emph{pBefore} renamed \emph{Pause_davor_min} and
#'   \emph{pAfter} renamed \emph{Pause_danach_min} and original columns
#'   \emph{iBeg} and \emph{iEnd} removed
#' 
#' @export
#' 
reformatEvents <- function(events)
{
  events <- kwb.event::hsEventsToUnit(events, tUnit = "min")
  
  events <- kwb.utils::hsRenameColumns(events, list(
    tBeg = "Ereignisbeginn_UTC",
    tEnd = "Ereignisende_UTC",
    dur = "Dauer_min",
    pBefore = "Pause_davor_min",
    pAfter = "Pause_danach_min"
  ))
  
  cbind(Nr = 1:nrow(events), events[, -(1:2)])
}

# writeHQSeriesToCSV -----------------------------------------------------------

#' Write H-Q-Series to CSV File
#' 
#' @param hqSeries data frame containing HQ time series
#' @param csv full path to csv file
#' @param sep column separator. Default: ";"
#' @param dec decimal character. Default: "."
#' 
#' @export
#' 
writeHQSeriesToCSV <- function(hqSeries, csv, sep = ";", dec = ",")
{
  cat("*** Writing HQ time series to", kwb.utils::windowsPath(csv), "... ")
  utils::write.table(
    hqSeries, csv, row.names = FALSE, sep = sep, dec = dec, na = ""
  )
  cat("ok.\n")
}

# writeEventListToCSV ----------------------------------------------------------

#' Write Event List to CSV File
#' 
#' @param events data frame containing event data
#' @param csv full path to csv file
#' @param sep column separator. Default: ";"
#' @param dec decimal character. Default: "."
#' 
#' @export
#' 
writeEventListToCSV <- function(events, csv, sep = ";", dec = ",")
{
  cat("*** Writing event list to", kwb.utils::windowsPath(csv), "... ")
  utils::write.table(
    events, csv, row.names = FALSE, sep = sep, dec = dec, na = ""
  )
  cat("ok.\n")
}

# dswtdir ----------------------------------------------------------------------

#' Path to Subfolder "DSWT" in tempdir()
#' 
#' Path to subfolder "DSWT" in tempdir(). If the subfolder does not yet exist
#'   it is created
#' 
#' @return path to subfolder "DSWT" in tempdir()
#' @export
dswtdir <- function()
{
  mydir <- file.path(tempdir(), "dswt")

  if (!file.exists(mydir)) {

    dir.create(mydir)
    cat(sprintf("directory \"%s\" created.\n", mydir))
  }

  mydir
}

# validate_HQ_relationships ----------------------------------------------------

#' Validate H-Q-Relationships
#' 
#' Validate HQ relationships for DN = 150 and DN = 300
#' 
#' @export
#' 
validate_HQ_relationships <- function()
{
  for (DN in c(150, 300)) {
    cat(sprintf("DN = %d\n", DN))
    validate_HQ_relationship(DN)
    hq <- H_Q_Table(DN)
    hq$calc <- round(H_to_Q(hq$H_m, DN), 3)
    print(hq)
  }
}

# validate_HQ_relationship -----------------------------------------------------

#' validate_HQ_relationship
#' 
#' Validate HQ relationship by plotting Q versus H from manufacturer table
#'   as points and the regression line given by the derived formula
#' @keywords internal
validate_HQ_relationship <- function(DN)
{
  hq <- H_Q_Table(DN)

  graphics::plot(
    hq$H_m, hq$Q_L_s, xlab = "H in m", ylab = "Q in L/s", 
    main = paste("DN", DN, sep=" = ")
  )
  
  h <- seq(0, max(hq$Q_L_s), by = 0.01)
  graphics::lines(h, H_to_Q(h, DN = DN), col = "blue")
}

# convertQUnits ----------------------------------------------------------------

#' Convert Q in L/h to L/s, m3/s and m3/h
#' 
#' @param hq data frame containing a column \emph{Q_L_h} containing flows in L/h
#' 
#' @return data frame with columns \emph{H_m, Q_L_s, Q_m3_s, Q_L_h, Q_m3_h}
#' 
convertQUnits <- function(hq)
{
  hq$Q_L_s  <- round(hq$Q_L_h / 3600, 3)
  hq$Q_m3_s <- round(hq$Q_L_h / 3600000, 6)
  hq$Q_m3_h <- round(hq$Q_L_h / 1000, 3)
  
  hq[, c("H_m", "Q_L_s", "Q_m3_s", "Q_L_h", "Q_m3_h")]
}

# H_Q_Table --------------------------------------------------------------------

#' H-Q-Relationship Given by Manufacturer
#' 
#' @param DN DN in mm, must be one of 150, 300
#' 
#' @return data frame with columns \emph{H_m, Q_L_s, Q_m3_s, Q_L_h, Q_m3_h}
#' 
H_Q_Table <- function(DN)
{
  if (DN == 150) {
    
    hq <- as.data.frame(.H_Q_Matrix_DN_150())
    
  } else if (DN == 300) {
    
    hq <- as.data.frame(.H_Q_Matrix_DN_300())
    
  } else {
    
    .stopWithNoSuchDN()
  }
  
  names(hq) <- c("H_m", "Q_L_h")
  convertQUnits(hq)
}

# H_to_Q -----------------------------------------------------------------------

#' Calculate Q from Height Above flume
#' 
#' Calculates Q from height h above flume as Q = a*H^b with a and be retrieved
#'   from linear regression between log(H) and log(Q) with H and Q values taken
#'   from manufacturer's table
#' 
#' @param H height above flume in m
#' @param DN DN in mm, must be one of 150, 300
#' 
H_to_Q <- function(H, DN)
{
  regressionCoefficients <- .regressionCoefficientsForDN(DN = DN)

  regressionCoefficients$a * H^regressionCoefficients$b
}

# Q_to_H -----------------------------------------------------------------------

#' Back-Calculate Height Above Flume From Discharge
#' 
#' back-calculates height H above flume from discharge Q.
#'   Q = a * H^b <=> H = (Q/a)^(1/b) with a and be retrieved from linear
#'   regression between log(H) and log(Q) with H and Q values taken from
#'   manufacturer's table
#' 
#' @param Q discharge Q in height above flume (in which unit?)
#' @param DN DN in mm, must be one of 150, 300
#' 
Q_to_H <- function(Q, DN)
{
  regressionCoefficients <- .regressionCoefficientsForDN(DN = DN)

  (Q/regressionCoefficients$a)^(1 / regressionCoefficients$b)
}

# .regressionCoefficientsForDN -------------------------------------------------
.regressionCoefficientsForDN <- function(DN) {
    if (DN == 150) {
        a <- exp(5.653)
        b <- 1.952
    }
    else if (DN == 300) {
        a <- 435.61
        b <- 1.9504
    }
    else {
        .stopWithNoSuchDN()
    }
    list(a = a, b = b)
}

# .stopWithNoSuchDN ------------------------------------------------------------
.stopWithNoSuchDN <- function() {
  stop("HQ relationship only available for DN = 150 or DN = 300")
}

# .wantedButNotAvailable -------------------------------------------------------
.wantedButNotAvailable <- function(cname, wanted, available) {
    cname %in% wanted & !(cname %in% available)
}

# .H_Q_Matrix_DN_150 -----------------------------------------------------------
.H_Q_Matrix_DN_150 <- function() {
  matrix(ncol = 2, byrow = TRUE, c(
    0.006, 47.54, 
    0.012, 183.68, 
    0.018, 404.99, 
    0.025, 768.5, 
    0.032, 1243.66, 
    0.038, 1738.75, 
    0.044, 2314.16, 
    0.050, 2969.28, 
    0.057, 3833.68, 
    0.063, 4659.87, 
    0.069, 5564.37,
    0.075, 6546.81, 
    0.082, 7791.07, 
    0.088, 8941.31, 
    0.094, 10168.56, 
    0.100, 11472.56, 
    0.107, 13090.57, 
    0.113, 14560.06, 
    0.119, 16105.59, 
    0.125, 17726.98, 
    0.132, 19714.21, 
    0.138, 21499.3, 
    0.144, 23359.69,
    0.150, 25295.2, 
    0.157, 27648.05, 
    0.163, 29745.82, 
    0.169, 31918.26, 
    0.176, 34546.96, 
    0.184, 37675.15, 
    0.191, 40520.54, 
    0.198, 43466.76, 
    0.205, 46513.63, 
    0.212, 49660.96, 
    0.219, 52908.59, 
    0.227, 56778.56
  ))
}

# .H_Q_Matrix_DN_300 -----------------------------------------------------------
.H_Q_Matrix_DN_300 <- function() {
  matrix(ncol = 2, byrow = TRUE, c(
    0.013, 329.11, 
    0.026, 1271.6, 
    0.039, 2803.69, 
    0.052, 4913.15, 
    0.065, 7591.62, 
    0.078, 10832.73, 
    0.091, 14631.35, 
    0.104, 18983.16, 
    0.117, 23884.49, 
    0.130, 29332.1, 
    0.143, 35323.11, 
    0.156, 41854.93, 
    0.169, 48925.21, 
    0.182, 56531.8, 
    0.195, 64672.72, 
    0.208, 73346.11, 
    0.221, 82550.28, 
    0.234, 92283.6, 
    0.247, 102544.57, 
    0.260, 113331.76, 
    0.273, 124643.82, 
    0.286, 136479.48, 
    0.299, 148837.52, 
    0.312, 161716.77, 
    0.325, 175116.13, 
    0.338, 189034.54, 
    0.351, 203470.98, 
    0.364, 218424.48, 
    0.377, 233894.09, 
    0.390, 249878.9, 
    0.403, 266378.06, 
    0.416, 283390.7, 
    0.429, 300916.03, 
    0.442, 318953.25, 
    0.457, 339846.98
  ))
}

# .siteNameToDN ----------------------------------------------------------------

#' Find DN for Given Site
#' 
#' @param sitename name of monitoring site
#' @export
.siteNameToDN <- function(sitename) {
  
  if (kwb.utils::isNullOrEmpty(sitename)) {
    stop("No sitename given!")
  }
  
  DNs <- list(T = 300, C = 150)
  
  sitegroupCode <- substr(sitename, 1, 1)
  
  if (!(sitegroupCode %in% names(DNs))) {
    stop("No DN given for sitename: ", sitename)
  }
  
  DN <- DNs[[sitegroupCode]]
  
  cat("DN at site", sitename, ":", DN, "\n")
  
  DN
}
