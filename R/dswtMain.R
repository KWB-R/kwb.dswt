# readAllLevelFiles ------------------------------------------------------------
readAllLevelFiles <- function # readAllLevelFiles
### readAllLevelFiles
(
  levelFiles,
  dbg = TRUE
)
{
  levelData <- NULL

  for (levelFile in levelFiles) {

    if (dbg) {
      cat("Reading", levelFile, "...\n")
    }

    newLevelData <- kwb.logger::readLogger_Ori_MLog(
      levelFile, sep = ";", stopOnMissingColumns = FALSE)

    newLevelData <- data.frame(
      file = basename(levelFile),
      row = 1:nrow(newLevelData),
      newLevelData,
      stringsAsFactors = FALSE)

    if (dbg) {
      cat("- Columns:", paste(kwb.utils::hsQuoteChr(names(newLevelData))), "\n")
      cat("ok.\n")
    }

    levelData <- kwb.utils::safeRowBind(levelData, newLevelData)
  }

  levelData
}

# getLevelFilesForSite ---------------------------------------------------------
getLevelFilesForSite <- function # levelFilesForSite
### levelFilesForSite
(
  config,
  station
)
{
  config$station <- station

  dictionary <- pathDictionary(
    dictionaryFile = config$dictionaryFile,
    settings = config
  )

  getDswtFilePaths(kwb.utils::resolve("LEVEL_DATA_DIR", dictionary),
                   DSWT_FILE_TYPES()$RADAR_PROBE_H)
}

# getDswtFilePaths -------------------------------------------------------------
getDswtFilePaths <- function # getDswtFilePaths
### browse for files of given type (DSWT-specific)
(
  srcdir,
  ### source directory
  filetype,
  ### one of the file types contained in DSWT_FILE_TYPES
  recursive = FALSE
  ### search in subdirectories?
)
{
  srcfiles <- dir(srcdir, pattern = filetype$pattern, full.names = TRUE,
                  recursive = recursive)

  if (kwb.utils::isNullOrEmpty(srcfiles)) {
    warning(sprintf("No files matching pattern '%s' found in %s\n",
                    filetype$pattern, srcdir))
    return()
  }

  srcfiles
}

# dirUploadedFiles -------------------------------------------------------------
dirUploadedFiles <- function # dirUploadedFiles
### dirUploadedFiles
(
  full.names=FALSE
)
{
  url <- "ftp://srv1-18557.srv-net.de/html/uploaded_files"
  subdirs <- c("PN", "H", "RD", "F", "LPR", "Q", "BPR")

  filepaths <- file.path(url, subdirs, "")
  names(filepaths)   <- subdirs

  uploadedFiles <- list()

  for (subdir in subdirs) {
    filenames <- dirFtpPath(filepaths[subdir], userpwd = "web1:FrurrEa",
                            full.names)

    uploadedFiles[[subdir]] <- filenames
  }

  uploadedFiles
  ### list with elements \emph{PN}, \emph{H}, \emph{RD}, \emph{F}, \emph{LPR},
  ### \emph{Q}, \emph{BPR} containing URLs to sampler files, water level files,
  ### rain data files, photos, laboratory protocol files, discharge files and
  ### operation protocol files, respectively, that are available at the DSWT
  ### server at sysprovide.de
}

# dirFtpPath -------------------------------------------------------------------
dirFtpPath <- function # dirFtpPath
### dirFtpPath
(
  url,
  userpwd,
  ### user and password, separated by colon ":"
  full.names = FALSE
)
{
  if (! requireNamespace("RCurl", quietly = TRUE)) {
    stop("Please install the package 'RCurl' first with ",
         "install.packages(\"RCurl\") in order to run dirFtpPath()")
  }

  filenames <- RCurl::getURL(url, userpwd = userpwd, ftp.use.epsv = FALSE,
                             dirlistonly = TRUE)
  filenames <- strsplit(filenames, "\r\n")[[1]]
  filenames <- setdiff(filenames, c(".", ".."))

  if (full.names) {
    filenames <- file.path(sub("/$", "", url), filenames)
  }

  filenames
}

# getHQSeriesFromCSV -----------------------------------------------------------
getHQSeriesFromCSV <- function # getHQSeriesFromCSV
### getHQSeriesFromCSV
(
  srcfile,
  ### full path to csv file generated by radar probe
  DN,
  ### DN in mm. Must be one of 150, 300.
  sep = "\t",
  ### column separator. Default: Tabulator "\\t"
  timeFormat = NULL,
  ### format of timestamp. Default: "%d.%m.%Y %H:%M"
  hoffset = 0.02,
  ### level offset to be subtracted from the measured level in order to get
  ### the level above the flume
  addTimeColumns = TRUE,
  ### if TRUE, time columns containing local date and time are added
  additionalColumns = c("I_mA", "Battery_V"),
  ### names of additional columns to be imported. One of c("I_mA", "Battery_V",
  ### "DeviceID")
  ...
  ### further arguments passed to readLogger_Ori_MLog, e.g.
  ### \emph{stopOnMissingColumns}
)
{
  if (is.null(timeFormat)) {
    timeFormat <- c("%d.%m.%Y %H:%M:%S", "%d.%m.%Y %H:%M")
  }

  myData <- kwb.logger::readLogger_Ori_MLog(srcfile, sep = sep, timeFormat = timeFormat, ...)

  if ("Level_cm" %in% names(myData)) {
    myData <- kwb.utils::hsRenameColumns(myData, list(Level_cm = "Hraw_cm"))
  }

  if (!"Hraw_m" %in% names(myData)) {
    kwb.utils::checkForMissingColumns(myData, "Hraw_cm")

    # convert cm to m and rename column
    myData$Hraw_cm <- myData$Hraw_cm / 100
    myData <- kwb.utils::hsRenameColumns(myData, list(Hraw_cm = "Hraw_m"))
  }

  hdat <- data.frame(
    BerlinDateTimeNoDST = myData$myDateTime,
    Hraw_m = myData$Hraw_m,
    stringsAsFactors = FALSE)

  if (length(additionalColumns) > 0) {
    hdat <- cbind(hdat, myData[, additionalColumns])
  }

  hdat <- correctHandCalculateQ(hdat, hoffset = hoffset, DN = DN)

  if (isTRUE(addTimeColumns)) {
    hdat <- insertLocalDateTimeColumns(hdat)
  }

  hdat
  ### data frame with columns \emph{BerlinDateTimeNoDST} (no daylight saving
  ### time adjustment!), \emph{Hraw_m} (measured height in m), \emph{H_m }
  ### (corrected height [= measured height minus offset] in m),\emph{Q_L_s}
  ### (calculated discharge in L/s). If \emph{addTimeColumns} is TRUE the
  ### columns \emph{BerlinDateTime} and \emph{UTCOffset} will be added.
}

# correctHandCalculateQ --------------------------------------------------------
correctHandCalculateQ <- function # correct level with offset and calculate Q
### correct level with offset and calculate Q
(
  hdat,
  ### data frame containing at least a column \emph{Hraw_m}, as e.g.
  ### retrieved by \code{readLogger_Ori_MLog}
  hoffset,
  ### offset in m to be subtracted from raw levels before the HQ relationship
  ### is applied
  DN
  ### DN in mm, must be one of 150, 300
)
{
  hdat$H_m <- hdat$Hraw_m - hoffset

  # Set H to 0 for H < 0
  hdat$H_m[hdat$H_m < 0] <- 0

  # calculate flow Q from H
  hdat$Q_L_s <- H_to_Q(hdat$H_m, DN)

  hdat
  ### data frame with additional columns \emph{H_m, Q_L_s}
}

# insertLocalDateTimeColumns ---------------------------------------------------
insertLocalDateTimeColumns <- function # insertLocalDateTimeColumns
### insertLocalDateTimeColumns
(
  mydata
  ### data frame with character column \emph{BerlinDateTimeNoDST}
)
{
  colname <- "BerlinDateTimeNoDST"
  winterTimeCol <- which(names(mydata) == colname)

  if(length(winterTimeCol) != 1) {
    stop(sprintf("No column \"%s\" found in data frame \"mydata\"!", colname))
  }

  berlinTime <- berlinNormalTimeToBerlinLocalTime(mydata[[winterTimeCol]])
  utcTime <- berlinNormalTimeToUTC(mydata[[winterTimeCol]])

  timesOnly <- data.frame(BerlinDateTimeNoDST = mydata[[winterTimeCol]],
                          BerlinDateTime = berlinTime,
                          UTCOffset = utcOffset(berlinTime, utcTime),
                          stringsAsFactors=FALSE)

  dataOnly <- mydata[, -winterTimeCol, drop=FALSE]

  cbind(timesOnly, dataOnly)
  ### data frame with additional columns \emph{BerlinDateTime} (character),
  ### \emph{UTCOffset} (numeric)
}

# insertUtcDateTimeColumn ------------------------------------------------------
insertUtcDateTimeColumn <- function # insertUtcDateTimeColumn
### insertUtcDateTimeColumn
(
  mydata
)
{
  utcTime <- berlinNormalTimeToUTC(mydata$BerlinDateTimeNoDST)
  cbind(mydata, DateTimeUTC = utcTime, stringsAsFactors = FALSE)
  ### mydata with additional column \emph{DateTimeUTC}
}

# completeTimeColumns ----------------------------------------------------------
completeTimeColumns <- function # completeTimeColumns
### completeTimeColumns
(
  x,
  ### data frame with time columns
  wanted=c("BerlinDateTime", "UTCOffset", "DateTimeUTC")
  ### Default: c("BerlinDateTime", "UTCOffset", "DateTimeUTC")
)
{
  cnames <- names(x)
  berlinTime <- NULL

  if (.wantedButNotAvailable("BerlinDateTime", wanted, cnames)) {
    if ("BerlinDateTimeNoDST" %in% cnames) {
      #berlinTime <- berlinWinterTimeToBerlinLocalTime(as.character(x$BerlinDateTimeNoDST))
      #x$BerlinDateTime <- berlinTime$charLocal
      x$BerlinDateTime <- berlinNormalTimeToBerlinLocalTime(as.character(x$BerlinDateTimeNoDST))
    }
  }

  if (.wantedButNotAvailable("UTCOffset", wanted, cnames)) {
    if (is.null(berlinTime) && "BerlinDateTimeNoDST" %in% cnames) {
      #berlinTime <- berlinWinterTimeToBerlinLocalTime(as.character(x$BerlinDateTimeNoDST))
      #x$UTCOffset <- berlinTime$utcOffset
      bnt <- as.character(x$BerlinDateTimeNoDST)
      x$UTCOffset <- utcOffset(berlinNormalTimeToBerlinLocalTime(bnt),
                               berlinNormalTimeToUTC(bnt))
    }
  }

  if (.wantedButNotAvailable("DateTimeUTC", wanted, cnames)) {
    if ("BerlinDateTimeNoDST" %in% cnames) {
      #utcTime <- berlinWinterTimeToUTC(as.character(x$BerlinDateTimeNoDST))
      #x$DateTimeUTC <- utcTime$charUTC
      x$DateTimeUTC <- berlinNormalTimeToUTC(as.character(x$BerlinDateTimeNoDST))
    }
  }
  x
  ### (Hopefully) data frame with columns \emph{BerlinDateTimeNoDST},
  ### \emph{BerlinDateTime}, \emph{UTCOffset}, \emph{DateTimeUTC},
}

# addTotalVolumeAndMaxQ --------------------------------------------------------
addTotalVolumeAndMaxQ <- function # addTotalVolumeAndMaxQ
### addTotalVolumeAndMaxQ
(
  qValues,
  ### vector of discharge values given in L/s
  events,
  ### event information as retrieved by \code{kwb.event::hsEvents}
  eventnr,
  ### integer vector of same length as \emph{qValues} giving the number of the
  ### event to which the Q value belongs, as returned by
  ### \code{kwb.event::hsEventNumber}.
  digitsV=3,
  ### number of decimal places for V in m3
  digitsMaxQ=3
  ### number of decimal places for max. Q in L/s
)
{
  # calculate total volume and max flow per event
  myby <- list(eventnr=eventnr)
  qsum <- aggregate(qValues, by=myby, FUN=sum)
  qmax <- aggregate(qValues, by=myby, FUN=max)

  signalWidth <- hsSigWidth(events)
  cat(sprintf("A signal width of %d seconds was deduced from the event list.\n",
              signalWidth))

  events$V_m3 <- round(qsum$x / 1000 * signalWidth, digitsV)
  events$maxQ_L_s <- round(qmax$x, digitsMaxQ)

  events
  ### \emph{events} with columns \emph{V_m3} and \emph{maxQ_L_s} added
}

# reformatEvents ---------------------------------------------------------------
reformatEvents <- function # reformat event list
### reformat event list: convert to minutes and rename columns
(
  events
  ### event list as retrieved by \code{kwb.event::hsEvents}
)
{
  events <- hsEventsToUnit(events, tUnit="min")
  events <- kwb.utils::hsRenameColumns(events, list(tBeg="Ereignisbeginn_UTC",
                                         tEnd="Ereignisende_UTC",
                                         dur="Dauer_min",
                                         pBefore="Pause_davor_min",
                                         pAfter="Pause_danach_min"))
  cbind(Nr=1:nrow(events), events[, -(1:2)])
  ### \emph{events} with \emph{tBeg} renamed \emph{Ereignisbeginn_UTC},
  ### \emph{tEnd} renamed \emph{Ereignisende_UTC}, \emph{dur} renamed
  ### \emph{Dauer_min}, \emph{pBefore} renamed \emph{Pause_davor_min} and
  ### \emph{pAfter} renamed \emph{Pause_danach_min} and original columns
  ### \emph{iBeg} and \emph{iEnd} removed
}

# writeHQSeriesToCSV -----------------------------------------------------------
writeHQSeriesToCSV <- function # writeHQSeriesToCSV
### writeHQSeriesToCSV
(
  hqSeries,
  ### data frame containing HQ time series
  csv,
  ### full path to csv file
  sep=";",
  ### column separator. Default: ";"
  dec=","
  ### decimal character. Default: "."
)
{
  cat("*** Writing HQ time series to", kwb.utils::windowsPath(csv), "... ")
  write.table(hqSeries, csv, row.names = FALSE, sep = sep, dec = dec, na = "")
  cat("ok.\n")
}

# writeEventListToCSV ----------------------------------------------------------
writeEventListToCSV <- function # writeEventListToCSV
### writeEventListToCSV
(
  events,
  ### data frame containing event data
  csv,
  ### full path to csv file
  sep = ";",
  ### column separator. Default: ";"
  dec = ","
  ### decimal character. Default: "."
)
{
  cat("*** Writing event list to", kwb.utils::windowsPath(csv), "... ")
  write.table(events, csv, row.names = FALSE, sep = sep, dec = dec, na = "")
  cat("ok.\n")
}

# dswtdir ----------------------------------------------------------------------
dswtdir <- function # path to subfolder "DSWT" in tempdir()
### path to subfolder "DSWT" in tempdir(). If the subfolder does not yet exist
### it is created
(
)
{
  mydir <- file.path(tempdir(), "dswt")

  if (!file.exists(mydir)) {

    dir.create(mydir)
    cat(sprintf("directory \"%s\" created.\n", mydir))
  }

  mydir
  ### path to subfolder "DSWT" in tempdir()
}

# validate_HQ_relationships ----------------------------------------------------
validate_HQ_relationships <- function # validate_HQ_relationships
### validate HQ relationships for DN = 150 and DN = 300
(
)
{
  for (DN in c(150, 300)) {
    cat(sprintf("DN = %d\n", DN))
    validate_HQ_relationship(DN)
    hq <- H_Q_Table(DN)
    hq$calc <- round(H_to_Q(hq$H_m, DN), 3)
    print(hq)
  }
}

# validate_HQ_relationship -----------------------------------------------------
validate_HQ_relationship <- function # validate_HQ_relationship
### validate HQ relationship by plotting Q versus H from manufacturer table
### as points and the regression line given by the derived formula
(
  DN
)
{
  hq <- H_Q_Table(DN)

  plot(hq$H_m, hq$Q_L_s, xlab = "H in m", ylab = "Q in L/s",
       main = paste("DN", DN, sep=" = "))

  h <- seq(0, max(hq$Q_L_s), by=0.01)
  lines(h, H_to_Q(h, DN=DN), col="blue")
}

# convertQUnits ----------------------------------------------------------------
convertQUnits <- function # convert Q in L/h to L/s, m3/s and m3/h
### convert Q in L/h to L/s, m3/s and m3/h
(
  hq
  ### data frame containing a column \emph{Q_L_h} containing flows in L/h
)
{
  hq$Q_L_s  <- round(hq$Q_L_h/3600, 3)
  hq$Q_m3_s <- round(hq$Q_L_h/3600000, 6)
  hq$Q_m3_h <- round(hq$Q_L_h/1000, 3)
  hq[, c("H_m", "Q_L_s", "Q_m3_s", "Q_L_h", "Q_m3_h")]
  ### data frame with columns \emph{H_m, Q_L_s, Q_m3_s, Q_L_h, Q_m3_h}
}

# H_Q_Table --------------------------------------------------------------------
H_Q_Table <- function # H/Q relationship given by manufacturer
### # H/Q relationship given by manufacturer
(
  DN
  ### DN in mm, must be one of 150, 300
)
{
  if (DN == 150) {
    hq <- as.data.frame(.H_Q_Matrix_DN_150())
  }
  else if (DN == 300) {
    hq <- as.data.frame(.H_Q_Matrix_DN_300())
  }
  else {
    .stopWithNoSuchDN()
  }
  names(hq) <- c("H_m", "Q_L_h")
  convertQUnits(hq)
  ### data frame with columns \emph{H_m, Q_L_s, Q_m3_s, Q_L_h, Q_m3_h}
}

# H_to_Q -----------------------------------------------------------------------
H_to_Q <- function # calculates Q from height h above flume
### calculates Q from height h above flume as Q = a*H^b with a and be retrieved
### from linear regression between log(H) and log(Q) with H and Q values taken
### from manufacturer's table
(
  H,
  ### height above flume in m
  DN
  ### DN in mm, must be one of 150, 300
)
{
  regressionCoefficients <- .regressionCoefficientsForDN(DN = DN)

  regressionCoefficients$a * H^regressionCoefficients$b
}

# Q_to_H -----------------------------------------------------------------------
Q_to_H <- function # back-calculates height H above flume from discharge Q
### back-calculates height H above flume from discharge Q.
### Q = a * H^b <=> H = (Q/a)^(1/b) with a and be retrieved from linear
### regression between log(H) and log(Q) with H and Q values taken from
### manufacturer's table
(
  Q,
  ### discharge Q in height above flume (in which unit?)
  DN
  ### DN in mm, must be one of 150, 300
)
{
  regressionCoefficients <- .regressionCoefficientsForDN(DN = DN)

  (Q/regressionCoefficients$a)^(1/regressionCoefficients$b)
}

# .regressionCoefficientsForDN -------------------------------------------------
.regressionCoefficientsForDN <- function
(
  DN
  ### DN in mm, must be one of 150, 300
)
{
  #  aus Datenblaettern der Steckrinnen in DN 150 (Clayallee) und DN 300
  #  (Treffurter Str.). Es muss also fuer die Clayallee mit einer anderen Formel
  #  gerechnet werden
  #  Treffurter Str.: a=285,28und b=1,9521.

  if (DN == 150) {
    # Call:
    #   lm(formula = log(Q_L_s) ~ log(H_m), data = H_Q_Table(150))
    # Coefficients:
    #   (Intercept)     log(H_m)
    # 5.653        1.952
    a <- exp(5.653)
    b <- 1.952
  }
  else if (DN == 300) {
    # Call:
    #   lm(formula = log(Q_L_s) ~ log(H_m), data = H_Q_Table(300))
    # Coefficients:
    #   (Intercept)     log(H_m)
    # 6.077        1.950
    a <- 435.61 # exp(6.077)
    b <- 1.9504 # 1.950
  }
  else {
    .stopWithNoSuchDN()
  }

  list(a = a, b = b)
  ### list with components \emph{a} and {b}, representing the coefficients to
  ### be used in formula Q = a*H^b
}

# .stopWithNoSuchDN ------------------------------------------------------------
.stopWithNoSuchDN <- function()
{
  stop("HQ relationship only available for DN = 150 or DN = 300")
}

# .wantedButNotAvailable -------------------------------------------------------
.wantedButNotAvailable <- function # .wantedButNotAvailable
### .wantedButNotAvailable
(
  cname,
  wanted,
  available
)
{
  cname %in% wanted & !(cname %in% available)
}

# .H_Q_Matrix_DN_150 -----------------------------------------------------------
.H_Q_Matrix_DN_150 <- function()
{
  matrix(c(0.006,47.54,
           0.012,183.68,
           0.018,404.99,
           0.025,768.50,
           0.032,1243.66,
           0.038,1738.75,
           0.044,2314.16,
           0.050,2969.28,
           0.057,3833.68,
           0.063,4659.87,
           0.069,5564.37,
           0.075,6546.81,
           0.082,7791.07,
           0.088,8941.31,
           0.094,10168.56,
           0.100,11472.56,
           0.107,13090.57,
           0.113,14560.06,
           0.119,16105.59,
           0.125,17726.98,
           0.132,19714.21,
           0.138,21499.30,
           0.144,23359.69,
           0.150,25295.20,
           0.157,27648.05,
           0.163,29745.82,
           0.169,31918.26,
           0.176,34546.96,
           0.184,37675.15,
           0.191,40520.54,
           0.198,43466.76,
           0.205,46513.63,
           0.212,49660.96,
           0.219,52908.59,
           0.227,56778.56), ncol=2, byrow=TRUE)
}

# .H_Q_Matrix_DN_300 -----------------------------------------------------------
.H_Q_Matrix_DN_300 <- function()
{
  matrix(c(0.013,329.11,
           0.026,1271.60,
           0.039,2803.69,
           0.052,4913.15,
           0.065,7591.62,
           0.078,10832.73,
           0.091,14631.35,
           0.104,18983.16,
           0.117,23884.49,
           0.130,29332.10,
           0.143,35323.11,
           0.156,41854.93,
           0.169,48925.21,
           0.182,56531.80,
           0.195,64672.72,
           0.208,73346.11,
           0.221,82550.28,
           0.234,92283.60,
           0.247,102544.57,
           0.260,113331.76,
           0.273,124643.82,
           0.286,136479.48,
           0.299,148837.52,
           0.312,161716.77,
           0.325,175116.13,
           0.338,189034.54,
           0.351,203470.98,
           0.364,218424.48,
           0.377,233894.09,
           0.390,249878.90,
           0.403,266378.06,
           0.416,283390.70,
           0.429,300916.03,
           0.442,318953.25,
           0.457,339846.98), ncol=2, byrow=TRUE)
}

# .siteNameToDN ----------------------------------------------------------------
.siteNameToDN <- function(sitename)
{
  if (kwb.utils::isNullOrEmpty(sitename)) {
    stop("No sitename given!")
  }

  DNs <- list(T = 300, C = 150)

  sitegroupCode <- substr(sitename, 1, 1)

  if (! (sitegroupCode %in% names(DNs))) {
    stop("No DN given for sitename: ", sitename)
  }

  DN <- DNs[[sitegroupCode]]

  cat("DN at site", sitename, ":", DN, "\n")

  DN
}
